{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Photodiode Analysis Code</h2>\n",
    "\n",
    "Ansley Kunnath\n",
    "\n",
    "Updated 04/15/24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting parameters from /Users/andrewkim/Desktop/PhotodiodeData/Kim_Andrew_2024-07-03_17-58-39.vhdr...\n",
      "Setting channel info structure...\n",
      "Used Annotations descriptions: ['Marker/Impedance', 'New Segment/', 'Stimulus/s1', 'Stimulus/s2', 'Stimulus/s3', 'Stimulus/s5']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m2/8_k5938s5_l8bzxcjsy3qyk00000gn/T/ipykernel_51485/745755210.py:20: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_brainvision(file_vhdr)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "########## Run with Python 3.9.12 (for Ansley)\n",
    "\n",
    "import mne\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.use(\"TkAgg\")\n",
    "import scipy.stats as stats\n",
    "#json import needed\n",
    "import json\n",
    "\n",
    "########## You may need to change the path and file name:\n",
    "eeg_path = \"/Users/andrewkim/Desktop/PhotodiodeData/\"  \n",
    "file_name = \"Kim_Andrew_2024-07-03_17-58-39\"\n",
    "file_eeg = eeg_path + file_name + \".eeg\"\n",
    "file_vhdr = eeg_path + file_name + \".vhdr\"\n",
    "file_vmrk = eeg_path + file_name + \".vmrk\"\n",
    "\n",
    "# Load and plot the raw data\n",
    "raw = mne.io.read_raw_brainvision(file_vhdr)\n",
    "events, event_id = mne.events_from_annotations(raw)\n",
    "\n",
    "#raw.crop(tmin=22, tmax=190)\n",
    "#raw.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "105 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 105 events and 1001 original time points ...\n",
      "0 bad epochs dropped\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    }
   ],
   "source": [
    "# Create epochs for checkerboard events\n",
    "\n",
    "stimulus_s1_events = events[events[:, 2] == event_id['Stimulus/s1']]\n",
    "stimulus_s1_events, event_id\n",
    "tmin, tmax = 0, 0.250  \n",
    "epochs = mne.Epochs(raw, events=stimulus_s1_events, event_id=event_id['Stimulus/s1'],\n",
    "                    tmin=tmin, tmax=tmax, baseline=None, preload=True)\n",
    "epochs = epochs.pick_channels(['BIP3'])\n",
    "\n",
    "#epochs.plot() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No exceedance found in epoch 10\n",
      "No exceedance found in epoch 20\n",
      "No exceedance found in epoch 24\n",
      "No exceedance found in epoch 28\n",
      "No exceedance found in epoch 30\n",
      "No exceedance found in epoch 40\n",
      "No exceedance found in epoch 41\n",
      "No exceedance found in epoch 43\n",
      "No exceedance found in epoch 48\n",
      "No exceedance found in epoch 50\n",
      "No exceedance found in epoch 57\n",
      "No exceedance found in epoch 60\n",
      "No exceedance found in epoch 70\n",
      "No exceedance found in epoch 80\n",
      "No exceedance found in epoch 90\n",
      "No exceedance found in epoch 100\n",
      "No exceedance found in epoch 102\n",
      "\n",
      "Median Latency: 60 ms\n",
      "95% Confidence Interval: (47.837, 71.163)\n",
      "Total Events: 88 out of 100\n",
      "Photodiode latencies saved to photodiode_latencies.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m2/8_k5938s5_l8bzxcjsy3qyk00000gn/T/ipykernel_51485/4145922955.py:10: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  for index, epoch in enumerate(epochs.get_data()):\n"
     ]
    }
   ],
   "source": [
    "# Calculate the first latency that exceeds # of MADs for each epoch \n",
    "\n",
    "########## CHANGE MAD_FACTOR\n",
    "mad_factor = 4 # or 2 to be less strict\n",
    "\n",
    "median_amplitude = []\n",
    "first_time = []\n",
    "peak_latencies = []\n",
    "\n",
    "for index, epoch in enumerate(epochs.get_data()):\n",
    "    positive_epoch = abs(epoch)*1000\n",
    "    median_amplitude = np.median(positive_epoch)\n",
    "    mad = np.median(np.abs(positive_epoch - median_amplitude))\n",
    "    threshold = median_amplitude + (mad_factor * mad)\n",
    "    exceed_index = np.argmax(positive_epoch > threshold)\n",
    "    if exceed_index > 0:\n",
    "        first_time = epochs.times[exceed_index] \n",
    "    else:\n",
    "        first_time = None \n",
    "        print(f\"No exceedance found in epoch {index}\") \n",
    "    peak_latencies.append(first_time)\n",
    "\n",
    "# Calculate latencies in milliseconds\n",
    "peak_latencies_ms = np.array([lat * 1000 if lat is not None else None for lat in peak_latencies])\n",
    "valid_latencies = peak_latencies_ms[peak_latencies_ms != np.array(None)]\n",
    "total_events = len(valid_latencies)\n",
    "\n",
    "# Calculate latency CI in milliseconds\n",
    "ncies_ms = np.array([lat * 1000 if lat is not None else None for lat in peak_latencies])\n",
    "valid_latencies = peak_latencies_ms[peak_latencies_ms != np.array(None)]\n",
    "\n",
    "# Calculate average and confidence interval only for valid latencies\n",
    "if len(valid_latencies) > 0:\n",
    "    median_latency_ms = np.median(valid_latencies)\n",
    "    sem_latency = stats.sem(valid_latencies)  # SEM = std / sqrt(n)\n",
    "    confidence_level = 0.95\n",
    "    ci_width = sem_latency * stats.t.ppf((1 + confidence_level) / 2, len(valid_latencies) - 1)\n",
    "    confidence_interval = (median_latency_ms - ci_width, median_latency_ms + ci_width)\n",
    "else:\n",
    "    median_latency_ms = None\n",
    "    confidence_interval = (None, None)\n",
    "\n",
    "print(\"\")\n",
    "print(f\"Median Latency: {median_latency_ms:.0f} ms\")\n",
    "print(f\"95% Confidence Interval: ({confidence_interval[0]:.3f}, {confidence_interval[1]:.3f})\")\n",
    "print(f\"Total Events: {total_events} out of 100\")\n",
    "\n",
    "#save the latency values separately\n",
    "peak_latencies_ms = [lat * 1000 if lat is not None else None for lat in peak_latencies]\n",
    "with open('photodiode_latencies.json', 'w') as f:\n",
    "    json.dump(peak_latencies_ms, f)\n",
    "\n",
    "print(\"Photodiode latencies saved to photodiode_latencies.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m2/8_k5938s5_l8bzxcjsy3qyk00000gn/T/ipykernel_51485/2414058590.py:8: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  epoch = epochs.get_data()[x]\n",
      "/var/folders/m2/8_k5938s5_l8bzxcjsy3qyk00000gn/T/ipykernel_51485/2414058590.py:8: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  epoch = epochs.get_data()[x]\n",
      "/var/folders/m2/8_k5938s5_l8bzxcjsy3qyk00000gn/T/ipykernel_51485/2414058590.py:8: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  epoch = epochs.get_data()[x]\n",
      "/var/folders/m2/8_k5938s5_l8bzxcjsy3qyk00000gn/T/ipykernel_51485/2414058590.py:8: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  epoch = epochs.get_data()[x]\n",
      "/var/folders/m2/8_k5938s5_l8bzxcjsy3qyk00000gn/T/ipykernel_51485/2414058590.py:8: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  epoch = epochs.get_data()[x]\n",
      "2024-07-05 13:21:48.660 Python[51485:8225401] WARNING: Secure coding is automatically enabled for restorable state! However, not on all supported macOS versions of this application. Opt-in to secure coding explicitly by implementing NSApplicationDelegate.applicationSupportsSecureRestorableState:.\n"
     ]
    }
   ],
   "source": [
    "# Plot individual epochs\n",
    "\n",
    "########## CHANGE X_VALUES BASED ON WHICH EPOCHS DID NOT EXCEED THE THRESHOLD\n",
    "x_values = [1, 2, 3, 4, 5]\n",
    "\n",
    "fig, axes = plt.subplots(len(x_values), 1, figsize=(10, 10), sharex=True, sharey=False)\n",
    "for i, x in enumerate(x_values):\n",
    "    epoch = epochs.get_data()[x]\n",
    "    abs_epoch = abs(epoch[0]) * 1000 \n",
    "    median_amplitude = np.median(abs_epoch)\n",
    "    mad = np.median(np.abs(abs_epoch - median_amplitude))\n",
    "    threshold = median_amplitude + (mad_factor * mad)\n",
    "    times_in_ms = epochs.times * 1000\n",
    "    exceed_index = np.argmax(abs_epoch > threshold)\n",
    "    if exceed_index > 0:\n",
    "        first_time = epochs.times[exceed_index] * 1000 \n",
    "    else:\n",
    "        first_time = None  # No point exceeded the threshold\n",
    "    \n",
    "    min_time = min(times_in_ms)\n",
    "    max_time = max(times_in_ms)\n",
    "    vertical_lines = np.arange(min_time, max_time, 2)\n",
    "\n",
    "    axes[i].plot(times_in_ms, abs_epoch)\n",
    "    axes[i].axvline(x=first_time if first_time is not None else 0, color='black', \n",
    "        label=f\"Screen Change: {first_time:.2f} ms\" if first_time is not None else \"Screen Change: None\")\n",
    "    axes[i].axhline(y=threshold, color='r', linestyle='--', label=f\"Threshold: {threshold:.2f} mV\")\n",
    "    axes[i].axhline(y=median_amplitude, color='b', linestyle='--', label=f\"Median: {median_amplitude:.2f} mV\")\n",
    "    for line in vertical_lines:\n",
    "        axes[i].axvline(x=line, color='gray', linestyle='--', linewidth=0.5, alpha=0.5)\n",
    "    axes[i].set_title(f\"Epoch {x}\")\n",
    "    axes[i].legend()\n",
    "\n",
    "plt.xlabel(\"Time (ms)\")\n",
    "plt.ylabel(\"Amplitude (mV)\")\n",
    "plt.savefig('Plot Epochs.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid command name \"6268111808process_stream_events\"\n",
      "    while executing\n",
      "\"6268111808process_stream_events\"\n",
      "    (\"after\" script)\n",
      "can't invoke \"event\" command:  application has been destroyed\n",
      "    while executing\n",
      "\"event generate $w <<ThemeChanged>>\"\n",
      "    (procedure \"ttk::ThemeChanged\" line 6)\n",
      "    invoked from within\n",
      "\"ttk::ThemeChanged\"\n"
     ]
    }
   ],
   "source": [
    "# Histogram of latency distributions\n",
    "\n",
    "########## SET BIN SIZE\n",
    "num_bins = 6 \n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bin_edges = np.linspace(min(valid_latencies), max(valid_latencies), num_bins + 1)\n",
    "rounded_bin_edges = np.round(bin_edges)\n",
    "n, bins, patches = plt.hist(valid_latencies, bins=bin_edges, edgecolor='black', linewidth=1.5)\n",
    "plt.xticks(rounded_bin_edges)\n",
    "for count, x in zip(n, bins[:-1]):\n",
    "    plt.text(x + (bins[1]-bins[0])/2, count, str(int(count)), ha='center', va='bottom')\n",
    "plt.title('Histogram of Latencies')\n",
    "plt.xlabel('Latency (ms)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.savefig('Histogram.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid command name \"6263422848process_stream_events\"\n",
      "    while executing\n",
      "\"6263422848process_stream_events\"\n",
      "    (\"after\" script)\n",
      "can't invoke \"event\" command:  application has been destroyed\n",
      "    while executing\n",
      "\"event generate $w <<ThemeChanged>>\"\n",
      "    (procedure \"ttk::ThemeChanged\" line 6)\n",
      "    invoked from within\n",
      "\"ttk::ThemeChanged\"\n"
     ]
    }
   ],
   "source": [
    "# Scatter plot of the latencies\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(range(len(valid_latencies)), valid_latencies, color='black')\n",
    "plt.axhline(median_latency_ms, color='red', linestyle='dashed', linewidth=2)\n",
    "plt.title('Scatter Plot of Latencies')\n",
    "plt.xlabel('Event')\n",
    "plt.ylabel('Latency (ms)')\n",
    "plt.grid(True)\n",
    "plt.savefig('Scatter Plot.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "33 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 33 events and 1001 original time points ...\n",
      "0 bad epochs dropped\n",
      "Need more than one channel to make topography for eeg. Disabling interactivity.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid command name \"13056630912process_stream_events\"\n",
      "    while executing\n",
      "\"13056630912process_stream_events\"\n",
      "    (\"after\" script)\n",
      "can't invoke \"event\" command:  application has been destroyed\n",
      "    while executing\n",
      "\"event generate $w <<ThemeChanged>>\"\n",
      "    (procedure \"ttk::ThemeChanged\" line 6)\n",
      "    invoked from within\n",
      "\"ttk::ThemeChanged\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x300 with 1 Axes>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "from mne.preprocessing import (ICA)\n",
    "from autoreject import AutoReject\n",
    "import matplotlib\n",
    "from autoreject import AutoReject\n",
    "\n",
    "#for storing and exchanging data\n",
    "import json\n",
    "matplotlib.use(\"TkAgg\")\n",
    "\n",
    "#load the photodiode latency data\n",
    "with open('photodiode_latencies.json', 'r') as f:\n",
    "    photodiode_latencies = json.load(f)\n",
    "\n",
    "# Adjust epoch start times based on photodiode latencies\n",
    "adjusted_events = []\n",
    "for event, latency in zip(events, photodiode_latencies):\n",
    "    if latency is not None:\n",
    "        adjusted_event = event.copy()\n",
    "        adjusted_event[0] += int(latency)  # Adjusting event start time by photodiode latency\n",
    "        adjusted_events.append(adjusted_event)\n",
    "\n",
    "adjusted_events = np.array(adjusted_events)\n",
    "\n",
    "# Create epochs with adjusted events\n",
    "tmin, tmax = 0, 0.250\n",
    "epochs = mne.Epochs(raw, events=adjusted_events, event_id=event_id['Stimulus/s1'], tmin=tmin, tmax=tmax, baseline=None, preload=True)\n",
    "\n",
    "# Continue with VEP analysis as usual\n",
    "evoked = epochs.average()\n",
    "evoked.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_path = \"C://Users//neuro//Documents//VEP//VEP Data//\"  # You will need to change this location\n",
    "file_name = \"AJK-03-01-24\"\n",
    "file_eeg = eeg_path + file_name + \".eeg\"\n",
    "file_vhdr = eeg_path + file_name + \".vhdr\"\n",
    "file_vmrk = eeg_path + file_name + \".vmrk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting parameters from C://Users//neuro//Documents//VEP//VEP Data//AJK-03-01-24.vhdr...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/andrewkim/Downloads/C:/Users/neuro/Documents/VEP/VEP Data/AJK-03-01-24.vhdr'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m raw \u001b[38;5;241m=\u001b[39m \u001b[43mmne\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_raw_brainvision\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_vhdr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#drop_channels = ['BIP1','BIP2','EOG','TEMP1','ACC1','ACC2','ACC3']\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#raw = raw.drop_channels(drop_channels)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#raw.plot()\u001b[39;00m\n\u001b[1;32m      5\u001b[0m events_from_annot, event_dict \u001b[38;5;241m=\u001b[39m mne\u001b[38;5;241m.\u001b[39mevents_from_annotations(raw)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/mne/io/brainvision/brainvision.py:956\u001b[0m, in \u001b[0;36mread_raw_brainvision\u001b[0;34m(vhdr_fname, eog, misc, scale, preload, verbose)\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;129m@fill_doc\u001b[39m\n\u001b[1;32m    917\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_raw_brainvision\u001b[39m(\n\u001b[1;32m    918\u001b[0m     vhdr_fname,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    923\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    924\u001b[0m ):\n\u001b[1;32m    925\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Reader for Brain Vision EEG file.\u001b[39;00m\n\u001b[1;32m    926\u001b[0m \n\u001b[1;32m    927\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    954\u001b[0m \u001b[38;5;124;03m    mne.io.Raw : Documentation of attributes and methods of RawBrainVision.\u001b[39;00m\n\u001b[1;32m    955\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 956\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mRawBrainVision\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvhdr_fname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvhdr_fname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m        \u001b[49m\u001b[43meog\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meog\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmisc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmisc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<decorator-gen-373>:12\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, vhdr_fname, eog, misc, scale, preload, verbose)\u001b[0m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/mne/io/brainvision/brainvision.py:92\u001b[0m, in \u001b[0;36mRawBrainVision.__init__\u001b[0;34m(self, vhdr_fname, eog, misc, scale, preload, verbose)\u001b[0m\n\u001b[1;32m     81\u001b[0m ext \u001b[38;5;241m=\u001b[39m op\u001b[38;5;241m.\u001b[39msplitext(hdr_fname)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     82\u001b[0m ahdr_format \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.ahdr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     83\u001b[0m (\n\u001b[1;32m     84\u001b[0m     info,\n\u001b[1;32m     85\u001b[0m     data_fname,\n\u001b[1;32m     86\u001b[0m     fmt,\n\u001b[1;32m     87\u001b[0m     order,\n\u001b[1;32m     88\u001b[0m     n_samples,\n\u001b[1;32m     89\u001b[0m     mrk_fname,\n\u001b[1;32m     90\u001b[0m     montage,\n\u001b[1;32m     91\u001b[0m     orig_units,\n\u001b[0;32m---> 92\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[43m_get_hdr_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhdr_fname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmisc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(data_fname, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fmt, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# ASCII, this will be slow :(\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/mne/io/brainvision/brainvision.py:514\u001b[0m, in \u001b[0;36m_get_hdr_info\u001b[0;34m(hdr_fname, eog, misc, scale)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.vhdr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.ahdr\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    509\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[1;32m    510\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe header file must be given to read the data, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    511\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot a file with extension \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m ext\n\u001b[1;32m    512\u001b[0m     )\n\u001b[0;32m--> 514\u001b[0m settings, cfg, cinfostr, info \u001b[38;5;241m=\u001b[39m \u001b[43m_aux_hdr_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhdr_fname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    515\u001b[0m info\u001b[38;5;241m.\u001b[39m_unlocked \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    517\u001b[0m order \u001b[38;5;241m=\u001b[39m cfg\u001b[38;5;241m.\u001b[39mget(cinfostr, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataOrientation\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/mne/io/brainvision/brainvision.py:411\u001b[0m, in \u001b[0;36m_aux_hdr_info\u001b[0;34m(hdr_fname)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_aux_hdr_info\u001b[39m(hdr_fname):\n\u001b[1;32m    410\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Aux function for _get_hdr_info.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 411\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhdr_fname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    412\u001b[0m         \u001b[38;5;66;03m# extract the first section to resemble a cfg\u001b[39;00m\n\u001b[1;32m    413\u001b[0m         header \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mreadline()\n\u001b[1;32m    414\u001b[0m         codepage \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/andrewkim/Downloads/C:/Users/neuro/Documents/VEP/VEP Data/AJK-03-01-24.vhdr'"
     ]
    }
   ],
   "source": [
    "raw = mne.io.read_raw_brainvision(file_vhdr)\n",
    "#drop_channels = ['BIP1','BIP2','EOG','TEMP1','ACC1','ACC2','ACC3']\n",
    "#raw = raw.drop_channels(drop_channels)\n",
    "#raw.plot()\n",
    "events_from_annot, event_dict = mne.events_from_annotations(raw)\n",
    "del event_dict['Stimulus/s5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highpass = 1\n",
    "lowpass = 20\n",
    "notch = 60\n",
    "\n",
    "raw_filtered = raw.load_data().filter(highpass, lowpass).notch_filter(np.arange(notch, (notch * 3), notch))\n",
    "#raw_filtered = raw.resample(resample).filter(highpass, lowpass).notch_filter(np.arange(notch, (notch * 3), notch))\n",
    "\n",
    "eeg_1020 = raw_filtered.copy().set_eeg_reference(ref_channels = 'average') # ref_channels='['Fz']'\n",
    "ten_twenty_montage = mne.channels.make_standard_montage('standard_1020')\n",
    "eeg_1020 = eeg_1020.set_montage(ten_twenty_montage, on_missing = 'ignore')\n",
    "#del raw, raw_filtered, ten_twenty_montage\n",
    "eeg_1020.info['bads'] = []\n",
    "picks = mne.pick_types(eeg_1020.info, meg=False, eeg=True, stim=False, eog=False, include=[], exclude=[])\n",
    "\n",
    "epochs = mne.Epochs(eeg_1020,\n",
    "                    events=events_from_annot,\n",
    "                    event_id=event_dict,\n",
    "                    tmin=-0.050,\n",
    "                    tmax=0.500,   #duration of stimulus or response\n",
    "                    baseline=None,\n",
    "                    reject=None,\n",
    "                    verbose=False,\n",
    "                    preload=True,\n",
    "                    detrend=None,\n",
    "                    event_repeated='drop')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_interpolates = np.array([1, 4, 32])\n",
    "consensus_percs = np.linspace(0, 1.0, 11)\n",
    "ar = AutoReject(n_interpolates,\n",
    "                consensus_percs,\n",
    "                picks=picks,\n",
    "                thresh_method='random_search',\n",
    "                random_state=42)    #random n state\n",
    "epochs_ar = ar.fit_transform(epochs);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica = ICA(n_components = 16, max_iter = 'auto', random_state = 123)\n",
    "ica.fit(epochs_ar)\n",
    "\n",
    "ica_z_thresh = 1.96\n",
    "epochs_clean = epochs_ar.copy()\n",
    "eog_indices, eog_scores = ica.find_bads_eog(epochs_clean,\n",
    "                                            ch_name=['Fp1', 'F8'],\n",
    "                                            threshold=ica_z_thresh)\n",
    "ica.exclude = eog_indices\n",
    "ica.plot_scores(eog_scores)\n",
    "ica.plot_sources(epochs_ar)\n",
    "ica.plot_components()\n",
    "print(eog_indices)\n",
    "ica.apply(epochs_clean)\n",
    "epochs_final = epochs_clean.copy()\n",
    "#del eeg_1020, epochs, epochs_ar, eog_indices, eog_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_tmin, baseline_tmax = -0.05, 0\n",
    "baseline = (baseline_tmin, baseline_tmax)\n",
    "\n",
    "VEP = epochs_final['Stimulus/s1'].apply_baseline(baseline).average()\n",
    "blank = epochs_final['Stimulus/s2'].apply_baseline(baseline).average()\n",
    "\n",
    "fig = mne.viz.plot_compare_evokeds(VEP, picks=['Oz','O1','O2'], combine=\"mean\", show=False, time_unit=\"ms\")\n",
    "fig[0].savefig(\"VEP Data/\"+file_name+\"-VEP_Occipital\")\n",
    "\n",
    "fig = mne.viz.plot_compare_evokeds(VEP, picks=['O1','O2'], combine=\"mean\", show=False, time_unit=\"ms\")\n",
    "fig[0].savefig(\"VEP Data/\"+file_name+\"-VEP_O1_O2\")\n",
    "\n",
    "fig = mne.viz.plot_compare_evokeds(VEP, picks=['Oz'], show=False, time_unit=\"ms\")\n",
    "fig[0].savefig(\"VEP Data/\"+file_name+\"-VEP_Oz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evokeds = dict(\n",
    "    Checkerboard=list(epochs_final['Stimulus/s1'].iter_evoked()),\n",
    "    Blank=list(epochs_final['Stimulus/s2'].iter_evoked()),\n",
    ")\n",
    "\n",
    "fig = mne.viz.plot_compare_evokeds(evokeds, \n",
    "                                   colors=dict(Checkerboard=\"red\", Blank=\"black\"), \n",
    "                                   ci=False, #0.95\n",
    "                                   picks=['Oz','O1','O2'], time_unit=\"ms\", combine=\"mean\")\n",
    "fig[0].savefig(\"VEP Data/\"+file_name+\"-Compare_Stimuli\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
