{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VEP Analysis Code\n",
    "AJK\n",
    "02-17-2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting parameters from Adam_VEP.vhdr...\n",
      "Setting channel info structure...\n",
      "Used Annotations descriptions: ['Marker/Impedance', 'New Segment/', 'Stimulus/s1', 'Stimulus/s2', 'Stimulus/s3', 'Stimulus/s5', 'Stimulus/s9007', 'Stimulus/s9008']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\neuro\\AppData\\Local\\Temp\\ipykernel_6864\\1107138427.py:16: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_brainvision(file_vhdr)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<details open>\n",
       "    <summary><strong>General</strong></summary>\n",
       "    <table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "        <tr>\n",
       "            <th>Measurement date</th>\n",
       "            \n",
       "            <td>May 06, 2024  13:14:30 GMT</td>\n",
       "            \n",
       "        </tr>\n",
       "        <tr>\n",
       "            <th>Experimenter</th>\n",
       "            \n",
       "            <td>Unknown</td>\n",
       "            \n",
       "        </tr>\n",
       "        <tr>\n",
       "            <th>Participant</th>\n",
       "            \n",
       "            <td>Unknown</td>\n",
       "            \n",
       "        </tr>\n",
       "    </table>\n",
       "    </details>\n",
       "    <details open>\n",
       "        <summary><strong>Channels</strong></summary>\n",
       "        <table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "            <tr>\n",
       "                <th>Digitized points</th>\n",
       "                \n",
       "                <td>Not available</td>\n",
       "                \n",
       "            </tr>\n",
       "            <tr>\n",
       "                <th>Good channels</th>\n",
       "                <td>64 EEG</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <th>Bad channels</th>\n",
       "                <td>None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <th>EOG channels</th>\n",
       "                <td>Not available</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <th>ECG channels</th>\n",
       "                <td>Not available</td>\n",
       "            </tr>\n",
       "        </table>\n",
       "        </details>\n",
       "        <details open>\n",
       "            <summary><strong>Data</strong></summary>\n",
       "            <table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "                \n",
       "                <tr>\n",
       "                    <th>Sampling frequency</th>\n",
       "                    <td>4000.00 Hz</td>\n",
       "                </tr>\n",
       "                \n",
       "                \n",
       "                <tr>\n",
       "                    <th>Highpass</th>\n",
       "                    <td>0.00 Hz</td>\n",
       "                </tr>\n",
       "                \n",
       "                \n",
       "                <tr>\n",
       "                    <th>Lowpass</th>\n",
       "                    <td>2000.00 Hz</td>\n",
       "                </tr>\n",
       "                \n",
       "                \n",
       "                \n",
       "                \n",
       "            </table>\n",
       "            </details>"
      ],
      "text/plain": [
       "<Info | 7 non-empty values\n",
       " bads: []\n",
       " ch_names: Fp1, Fpz, Fp2, F7, F3, Fz, F4, F8, FC5, FC1, FC2, FC6, M1, T7, ...\n",
       " chs: 64 EEG\n",
       " custom_ref_applied: False\n",
       " highpass: 0.0 Hz\n",
       " lowpass: 2000.0 Hz\n",
       " meas_date: 2024-05-06 13:14:30 UTC\n",
       " nchan: 64\n",
       " projs: []\n",
       " sfreq: 4000.0 Hz\n",
       ">"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load packages and data\n",
    "\n",
    "import mne\n",
    "import numpy as np\n",
    "from mne.preprocessing import (ICA)\n",
    "#from autoreject import AutoReject\n",
    "import matplotlib\n",
    "matplotlib.use(\"TkAgg\")\n",
    "\n",
    "eeg_path = \"Adam_VEP\"  # You will need to change the file name\n",
    "\n",
    "file_eeg = eeg_path + \".eeg\"\n",
    "file_vhdr = eeg_path + \".vhdr\"\n",
    "file_vmrk = eeg_path + \".vmrk\"\n",
    "\n",
    "raw = mne.io.read_raw_brainvision(file_vhdr)\n",
    "#drop_channels = ['BIP2','EOG','TEMP1','ACC1','ACC2','ACC3']\n",
    "#raw = raw.drop_channels(drop_channels)\n",
    "events_from_annot, event_dict = mne.events_from_annotations(raw)\n",
    "del event_dict['Stimulus/s5']\n",
    "#raw.set_channel_types({'BIP1':'ecg'})\n",
    "raw.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 0 ... 934717  =      0.000 ...   233.679 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.5 - 40 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.50\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
      "- Upper passband edge: 40.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 45.00 Hz)\n",
      "- Filter length: 26401 samples (6.600 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-stop filter\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower transition bandwidth: 0.50 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz\n",
      "- Filter length: 26401 samples (6.600 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n"
     ]
    }
   ],
   "source": [
    "# Filter data and create epochs\n",
    "\n",
    "highpass = 0.5\n",
    "lowpass = 40\n",
    "notch = 60\n",
    "\n",
    "raw_filtered = raw.load_data().filter(highpass, lowpass).notch_filter(np.arange(notch, (notch * 3), notch))\n",
    "eeg_1020 = raw_filtered.copy().set_eeg_reference(ref_channels = 'average') #['Fz'])\n",
    "ten_twenty_montage = mne.channels.make_standard_montage('standard_1020')\n",
    "eeg_1020 = eeg_1020.set_montage(ten_twenty_montage, on_missing = 'ignore')\n",
    "eeg_1020.info['bads'] = []\n",
    "eeg_1020.plot()\n",
    "picks = mne.pick_types(eeg_1020.info, meg=False, eeg=True, stim=False, eog=False, include=[], exclude=[])\n",
    "\n",
    "epochs = mne.Epochs(eeg_1020,\n",
    "                    events=events_from_annot,\n",
    "                    event_id=event_dict,\n",
    "                    tmin=-0.050,\n",
    "                    tmax=0.300,   #duration of stimulus or response\n",
    "                    baseline=None,\n",
    "                    reject=None,\n",
    "                    verbose=False,\n",
    "                    preload=True,\n",
    "                    detrend=None,\n",
    "                    event_repeated='drop')\n",
    "\n",
    "del raw, raw_filtered, ten_twenty_montage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AutoReject' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m n_interpolates \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m32\u001b[39m])\n\u001b[0;32m      4\u001b[0m consensus_percs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;241m11\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m ar \u001b[38;5;241m=\u001b[39m \u001b[43mAutoReject\u001b[49m(n_interpolates,\n\u001b[0;32m      6\u001b[0m                 consensus_percs,\n\u001b[0;32m      7\u001b[0m                 picks\u001b[38;5;241m=\u001b[39mpicks,\n\u001b[0;32m      8\u001b[0m                 thresh_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom_search\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      9\u001b[0m                 random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)  \n\u001b[0;32m     10\u001b[0m epochs_ar \u001b[38;5;241m=\u001b[39m ar\u001b[38;5;241m.\u001b[39mfit_transform(epochs)\n\u001b[0;32m     11\u001b[0m epochs_ar\u001b[38;5;241m.\u001b[39mplot()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'AutoReject' is not defined"
     ]
    }
   ],
   "source": [
    "# Run AutoReject to find bad epochs\n",
    "\n",
    "n_interpolates = np.array([1, 4, 32])\n",
    "consensus_percs = np.linspace(0, 1.0, 11)\n",
    "ar = AutoReject(n_interpolates,\n",
    "                consensus_percs,\n",
    "                picks=picks,\n",
    "                thresh_method='random_search',\n",
    "                random_state=42)  \n",
    "epochs_ar = ar.fit_transform(epochs)\n",
    "epochs_ar.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting ICA to data using 63 channels (please be patient, this may take a while)\n",
      "Selecting by number: 30 components\n",
      "Fitting ICA took 31.5s.\n",
      "[]\n",
      "Applying ICA to Epochs instance\n",
      "    Transforming to ICA space (30 components)\n",
      "    Zeroing out 0 ICA components\n",
      "    Projecting back using 63 PCA components\n",
      "Opening epochs-browser...\n"
     ]
    }
   ],
   "source": [
    "# Use ICA to remove cardiac artifacts\n",
    "\n",
    "ica = ICA(n_components = 30, max_iter = 'auto', random_state = 123)\n",
    "ica.fit(epochs_ar)\n",
    "ica_z_thresh = 1.96\n",
    "ica.exclude = []\n",
    "epochs_clean = epochs_ar.copy()\n",
    "ecg_indices, ecg_scores = ica.find_bads_ecg(epochs_clean,\n",
    "                                            threshold=ica_z_thresh)\n",
    "ica.exclude = ecg_indices\n",
    "print(ecg_indices)\n",
    "ica.apply(epochs_clean)\n",
    "epochs_final = epochs_clean.copy()\n",
    "epochs_final.plot()\n",
    "\n",
    "del eeg_1020, epochs, epochs_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.4.2-cp39-cp39-win_amd64.whl (10.6 MB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\neuro\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\neuro\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn) (1.13.0)\n",
      "Collecting joblib>=1.2.0\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.4.2 threadpoolctl-3.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 24.0 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\neuro\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting ICA to data using 64 channels (please be patient, this may take a while)\n",
      "Selecting by number: 20 components\n",
      "Fitting ICA took 1.7s.\n",
      "Applying ICA to Epochs instance\n",
      "    Transforming to ICA space (20 components)\n",
      "    Zeroing out 3 ICA components\n",
      "    Projecting back using 64 PCA components\n"
     ]
    }
   ],
   "source": [
    "# Manual ICA analysis (optional)\n",
    "\n",
    "########################################\n",
    "ica = ICA(n_components = 20, max_iter = 'auto', random_state = 123)\n",
    "ica.fit(epochs)\n",
    "#ica.plot_sources(epochs)\n",
    "#ica.plot_components()\n",
    "#ica.plot_properties(epochs)\n",
    "\n",
    "exclude = [0, 1, 5]    # select based on ICA abnl. OPTIONAL.\n",
    "epochs_clean = epochs.copy()\n",
    "ica.exclude = exclude\n",
    "ica.apply(epochs_clean)\n",
    "epochs_clean.plot(n_channels = len(epochs_clean))\n",
    "epochs_final = epochs_clean.copy()\n",
    "\n",
    "## if no ICAs:\n",
    "#epochs_final = epochs_clean.copy()\n",
    "#del eeg_1020, epochs, epochs_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying baseline correction (mode: mean)\n",
      "Applying baseline correction (mode: mean)\n"
     ]
    }
   ],
   "source": [
    "# Average epochs by condition\n",
    "\n",
    "VEP = epochs_final['Stimulus/s3'].apply_baseline().average()\n",
    "blank = epochs_final['Stimulus/s2'].apply_baseline().average()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combining channels using \"mean\"\n",
      "combining channels using \"mean\"\n"
     ]
    }
   ],
   "source": [
    "# Plot VEP\n",
    "fig = mne.viz.plot_compare_evokeds(VEP, picks=['Oz'], show=True)\n",
    "fig[0].savefig(\"VEP_Oz\")\n",
    "\n",
    "fig = mne.viz.plot_compare_evokeds(dict(Checkboard=VEP, Blank=blank), colors=dict(Checkboard=\"orange\", Blank=\"black\"), picks=['Oz', 'O1', 'O2'], combine=\"mean\")\n",
    "fig[0].savefig(\"VEP_Comparison_Occipital\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** PEAK MEASURES ***\n",
      "Channel: O2\n",
      "Time Window: 50.000 - 150.000 ms\n",
      "Peak Latency: 130.000 ms\n",
      "Peak Amplitude: 2.234 µV\n",
      "*** TROUGH MEASURES ***\n",
      "Channel: O1\n",
      "Time Window: 50.000 - 150.000 ms\n",
      "Peak Latency: 86.000 ms\n",
      "Peak Amplitude: -2.070 µV\n"
     ]
    }
   ],
   "source": [
    "# Evaluate VEP properties\n",
    "\n",
    "def print_peak_measures(ch, tmin, tmax, lat, amp):\n",
    "    print(f\"Channel: {ch}\")\n",
    "    print(f\"Time Window: {tmin * 1e3:.3f} - {tmax * 1e3:.3f} ms\")\n",
    "    print(f\"Peak Latency: {lat * 1e3:.3f} ms\")\n",
    "    print(f\"Peak Amplitude: {amp * 1e6:.3f} µV\")\n",
    "\n",
    "VEP_ROI = VEP.copy().pick(['Oz','O1','O2'])\n",
    "\n",
    "good_tmin, good_tmax = 0.05, 0.15\n",
    "ch, lat, amp = VEP_ROI.get_peak(\n",
    "    ch_type=\"eeg\", tmin=good_tmin, tmax=good_tmax, mode=\"pos\", return_amplitude=True\n",
    ")\n",
    "print(\"*** PEAK MEASURES ***\")\n",
    "print_peak_measures(ch, good_tmin, good_tmax, lat, amp)\n",
    "\n",
    "\n",
    "good_tmin, good_tmax = 0.05, 0.15\n",
    "ch, lat, amp = VEP_ROI.get_peak(\n",
    "    ch_type=\"eeg\", tmin=good_tmin, tmax=good_tmax, mode=\"neg\", return_amplitude=True\n",
    ")\n",
    "print(\"*** TROUGH MEASURES ***\")\n",
    "print_peak_measures(ch, good_tmin, good_tmax, lat, amp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
