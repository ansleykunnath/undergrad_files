{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'autoreject'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmne\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (ICA)\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mautoreject\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoReject\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\n\u001b[0;32m      6\u001b[0m matplotlib\u001b[38;5;241m.\u001b[39muse(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTkAgg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'autoreject'"
     ]
    }
   ],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "from mne.preprocessing import (ICA)\n",
    "from autoreject import AutoReject\n",
    "import matplotlib\n",
    "matplotlib.use(\"TkAgg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_path = \"C://Users//neuro//Documents//Git_EEG_Workshop//EEG_Workshop//Data//\"  # You will need to change this location\n",
    "file_name = \"VEP_2024-07-05_15-17-52\"\n",
    "file_eeg = eeg_path + file_name + \".eeg\"\n",
    "file_vhdr = eeg_path + file_name + \".vhdr\"\n",
    "file_vmrk = eeg_path + file_name + \".vmrk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting parameters from C://Users//neuro//Documents//VEP//VEP Data//AJK-03-01-24.vhdr...\n",
      "Setting channel info structure...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\neuro\\AppData\\Local\\Temp\\ipykernel_4052\\2967754227.py:1: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_brainvision(file_vhdr)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib as 2D backend.\n",
      "Used Annotations descriptions: ['Marker/Impedance', 'New Segment/', 'Stimulus/s1', 'Stimulus/s2', 'Stimulus/s3', 'Stimulus/s5', 'Stimulus/s9007', 'Stimulus/s9008']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels marked as bad:\n",
      "none\n"
     ]
    }
   ],
   "source": [
    "raw = mne.io.read_raw_brainvision(file_vhdr)\n",
    "#drop_channels = ['BIP1','BIP2','EOG','TEMP1','ACC1','ACC2','ACC3']\n",
    "#raw = raw.drop_channels(drop_channels)\n",
    "#raw.plot()\n",
    "events_from_annot, event_dict = mne.events_from_annotations(raw)\n",
    "del event_dict['Stimulus/s5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 0 ... 84538  =      0.000 ...   169.076 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 20 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 20.00 Hz\n",
      "- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n",
      "- Filter length: 1651 samples (3.302 s)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-stop filter\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower transition bandwidth: 0.50 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz\n",
      "- Filter length: 3301 samples (6.602 s)\n",
      "\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n"
     ]
    }
   ],
   "source": [
    "highpass = 1\n",
    "lowpass = 20\n",
    "notch = 60\n",
    "\n",
    "raw_filtered = raw.load_data().filter(highpass, lowpass).notch_filter(np.arange(notch, (notch * 3), notch))\n",
    "#raw_filtered = raw.resample(resample).filter(highpass, lowpass).notch_filter(np.arange(notch, (notch * 3), notch))\n",
    "\n",
    "eeg_1020 = raw_filtered.copy().set_eeg_reference(ref_channels = 'average') # ref_channels='['Fz']'\n",
    "ten_twenty_montage = mne.channels.make_standard_montage('standard_1020')\n",
    "eeg_1020 = eeg_1020.set_montage(ten_twenty_montage, on_missing = 'ignore')\n",
    "#del raw, raw_filtered, ten_twenty_montage\n",
    "eeg_1020.info['bads'] = []\n",
    "picks = mne.pick_types(eeg_1020.info, meg=False, eeg=True, stim=False, eog=False, include=[], exclude=[])\n",
    "\n",
    "epochs = mne.Epochs(eeg_1020,\n",
    "                    events=events_from_annot,\n",
    "                    event_id=event_dict,\n",
    "                    tmin=-0.050,\n",
    "                    tmax=0.500,   #duration of stimulus or response\n",
    "                    baseline=None,\n",
    "                    reject=None,\n",
    "                    verbose=False,\n",
    "                    preload=True,\n",
    "                    detrend=None,\n",
    "                    event_repeated='drop')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\neuro\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running autoreject on ch_type=eeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| Creating augmented epochs : 33/33 [00:00<00:00,   90.17it/s]\n",
      "100%|██████████| Computing thresholds ... : 33/33 [00:04<00:00,    6.84it/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| Repairing epochs : 162/162 [00:00<00:00,  633.21it/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| Repairing epochs : 162/162 [00:01<00:00,  154.31it/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| Fold : 10/10 [00:01<00:00,    5.43it/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| Repairing epochs : 162/162 [00:01<00:00,  149.43it/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| Fold : 10/10 [00:01<00:00,    6.35it/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| Repairing epochs : 162/162 [00:01<00:00,  142.08it/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| Fold : 10/10 [00:00<00:00,   41.69it/s]\n",
      "100%|██████████| n_interp : 3/3 [00:07<00:00,    2.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Estimated consensus=0.50 and n_interpolate=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| Repairing epochs : 162/162 [00:01<00:00,  145.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 37 epochs: 0, 1, 2, 5, 7, 8, 9, 11, 12, 16, 22, 23, 26, 27, 28, 36, 39, 40, 43, 58, 65, 66, 68, 69, 72, 74, 86, 97, 99, 102, 103, 112, 129, 131, 133, 145, 161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_interpolates = np.array([1, 4, 32])\n",
    "consensus_percs = np.linspace(0, 1.0, 11)\n",
    "ar = AutoReject(n_interpolates,\n",
    "                consensus_percs,\n",
    "                picks=picks,\n",
    "                thresh_method='random_search',\n",
    "                random_state=42)    #random n state\n",
    "epochs_ar = ar.fit_transform(epochs);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting ICA to data using 33 channels (please be patient, this may take a while)\n",
      "Selecting by number: 16 components\n",
      "Fitting ICA took 1.0s.\n",
      "Using EOG channels: Fp1, F8\n",
      "Not setting metadata\n",
      "125 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "[0, 11]\n",
      "Applying ICA to Epochs instance\n",
      "    Transforming to ICA space (16 components)\n",
      "    Zeroing out 2 ICA components\n",
      "    Projecting back using 33 PCA components\n"
     ]
    }
   ],
   "source": [
    "ica = ICA(n_components = 16, max_iter = 'auto', random_state = 123)\n",
    "ica.fit(epochs_ar)\n",
    "\n",
    "ica_z_thresh = 1.96\n",
    "epochs_clean = epochs_ar.copy()\n",
    "eog_indices, eog_scores = ica.find_bads_eog(epochs_clean,\n",
    "                                            ch_name=['Fp1', 'F8'],\n",
    "                                            threshold=ica_z_thresh)\n",
    "ica.exclude = eog_indices\n",
    "ica.plot_scores(eog_scores)\n",
    "ica.plot_sources(epochs_ar)\n",
    "ica.plot_components()\n",
    "print(eog_indices)\n",
    "ica.apply(epochs_clean)\n",
    "epochs_final = epochs_clean.copy()\n",
    "#del eeg_1020, epochs, epochs_ar, eog_indices, eog_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 14) (436900637.py, line 14)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[28], line 14\u001b[1;36m\u001b[0m\n\u001b[1;33m    fig[0].savefig(\"\"VEP Data/\"+file_name+\"-VEP_Oz\")\u001b[0m\n\u001b[1;37m                                                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unterminated string literal (detected at line 14)\n"
     ]
    }
   ],
   "source": [
    "baseline_tmin, baseline_tmax = -0.05, 0\n",
    "baseline = (baseline_tmin, baseline_tmax)\n",
    "\n",
    "VEP = epochs_final['Stimulus/s1'].apply_baseline(baseline).average()\n",
    "blank = epochs_final['Stimulus/s2'].apply_baseline(baseline).average()\n",
    "\n",
    "fig = mne.viz.plot_compare_evokeds(VEP, picks=['Oz','O1','O2'], combine=\"mean\", show=False, time_unit=\"ms\")\n",
    "fig[0].savefig(\"VEP Data/\"+file_name+\"-VEP_Occipital\")\n",
    "\n",
    "fig = mne.viz.plot_compare_evokeds(VEP, picks=['O1','O2'], combine=\"mean\", show=False, time_unit=\"ms\")\n",
    "fig[0].savefig(\"VEP Data/\"+file_name+\"-VEP_O1_O2\")\n",
    "\n",
    "fig = mne.viz.plot_compare_evokeds(VEP, picks=['Oz'], show=False, time_unit=\"ms\")\n",
    "fig[0].savefig(\"VEP Data/\"+file_name+\"-VEP_Oz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combining channels using \"mean\"\n",
      "combining channels using \"mean\"\n"
     ]
    }
   ],
   "source": [
    "evokeds = dict(\n",
    "    Checkerboard=list(epochs_final['Stimulus/s1'].iter_evoked()),\n",
    "    Blank=list(epochs_final['Stimulus/s2'].iter_evoked()),\n",
    ")\n",
    "\n",
    "fig = mne.viz.plot_compare_evokeds(evokeds, \n",
    "                                   colors=dict(Checkerboard=\"red\", Blank=\"black\"), \n",
    "                                   ci=False, #0.95\n",
    "                                   picks=['Oz','O1','O2'], time_unit=\"ms\", combine=\"mean\")\n",
    "fig[0].savefig(\"VEP Data/\"+file_name+\"-Compare_Stimuli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
